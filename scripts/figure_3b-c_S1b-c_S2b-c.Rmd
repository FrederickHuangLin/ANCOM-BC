---
title: "Figure 3b-c, S1b-c, S2b-c"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
rm(list = ls())

library(tidyverse)
library(phyloseq)
library(ggpubr)
library(RColorBrewer)
library(DT)
library(pander)
panderOptions('table.caption.prefix', NULL)
panderOptions('table.continues', NULL)
panderOptions('table.emphasize.rownames', FALSE)

source("sim_data_poi_gam_two_grp.R")
source("ancom_bc_v1.0.R")
source("ancom_simple.R")
```

# 1. Monte Carlo Simulations

## 1.1 Simulation Settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, library size, and sample size
n.taxa=1000; samp.frac.var="large"; n.samp=c("20_30", "50_50")

# The proportion of differentially abundant taxa
prop.diff=c(0.05, 0.15, 0.25)

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed, samp.frac.var)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed", "samp.frac.var")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", 
                  "abn.seed", "samp.frac.var", "obs.seed")
```

## 1.2 ANCOM-BC

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(4, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_ancom_bc_large.csv")
```

## 1.3 ANCOM

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(10, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  feature.table.origin=test.dat$obs.abn
  
  # Pre-processing
  pre.process=feature_table_pre_process(feature.table.origin, meta.data, 
                                        sample.var="Sample.ID", group.var="group",
                                        zero.cut=0.90, lib.cut=1000, neg.lb = FALSE)
  struc.zero=pre.process$structure.zeros
  num.struc.zero=apply(struc.zero, 1, sum)
  feature.table=pre.process$feature.table
  s0=rownames(feature.table)[which(num.struc.zero==0)]
  s1=rownames(feature.table)[which(num.struc.zero==1)]
  
  # Run ANCOM
  # Format for ANCOM: rows = subjects, cols=taxa
  feature.table.sub=t(feature.table[s0, ])
  
  res.W=ANCOM.main(OTUdat=feature.table.sub, Vardat=meta.data, 
                   main.var="group", sig=0.05, prev.cut=1.01)
  
  res=data.frame(otu.names=c(s0, s1), W_stat=Inf, detected_0.9=TRUE,
                 detected_0.8=TRUE, detected_0.7=TRUE, detected_0.6=TRUE)
  res[match(as.character(res.W$otu.names), res$otu.names), ]=res.W
  res$diff.ind=test.dat$diff.taxa[c(s0, s1)]
  
  # FDR
  FDR=ifelse(sum(res$detected_0.7, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$detected_0.7, 1, 0), na.rm = T)/
               sum(res$detected_0.7, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$detected_0.7, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_ancom_large.csv")
```

## 1.4 DESeq2

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(DESeq2)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for DESeq2
  countdata=test.dat$obs.abn # Format for DESeq2: taxa are rows
  coldata=data.frame(group=as.factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2))))
  rownames(coldata)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  count.table=DESeqDataSetFromMatrix(
    countData = feature_table, colData = coldata, design = ~ group)
  
  # Run DESeq2
  suppressWarnings(dds <- try(DESeq(count.table, quiet = TRUE), silent = TRUE))
  if (inherits(dds, "try-error")) {
    # If the parametric fit failed, try the local.
    suppressWarnings(dds <- try(DESeq(count.table, fitType = "local", quiet = TRUE), silent = TRUE))
    if (inherits(dds, "try-error")) {
      # If local fails, try the mean
      suppressWarnings(dds <- try(DESeq(count.table, fitType = "mean", quiet = TRUE), silent = TRUE))
    }
  }
  if (inherits(dds, "try-error")) {
    # If still bad
    FDR=NA; power=NA
  }else{
    res = results(dds)
    res$id = rownames(res)
    # Some DESeq2 results (for example) had NA adjusted p-values, so replace them with 1
    res[is.na(res[, "padj"]), "padj"] = 1
    
    res=data.frame(taxa=res$id,
                   diff.test=ifelse(res$padj<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)],
                   effec.size=test.dat$effect.size[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
    
  }
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_deseq2_large.csv")

```

## 1.5 edgeR

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(edgeR)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for edgeR
  groupdata=factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn; meta.data=data.frame(group=groupdata)
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  d=DGEList(counts = countdata, group = groupdata)
  d=calcNormFactors(d)
  design.mat=model.matrix(~ 0 + d$samples$group)
  colnames(design.mat)=levels(d$samples$group)
  
  d=estimateDisp(d, design.mat)
  fit=glmQLFit(d, design.mat)
  qlf=glmQLFTest(fit, contrast=c(1, -1))
  out=data.frame(taxa=rownames(topTags(qlf, n=nrow(countdata))$table), 
                 FDR=topTags(qlf, n=nrow(countdata))$table$FDR)
  out=out[match(rownames(countdata), as.character(out$taxa)), ]
  out$FDR[is.na(out$FDR)]=1
  
  res=data.frame(diff.test=ifelse(out$FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
               sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_edger_large.csv")
```

## 1.6 metagenomeSeq: Zero-inflated log-normal mixture model (ZILG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  suppressWarnings(fit <- try(fitFeatureModel(obj, mod)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_zilg_large.csv")
```

## 1.7 metagenomeSeq: Zero-inflated gaussian mixture model (ZIG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  settings = zigControl(maxit = 100, verbose = F)
  suppressWarnings(fit <- try(fitZig(obj, mod, useCSSoffset = T, control = settings)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_zig_large.csv")
```

## 1.8 Wilcoxon rank-sum test: Unnormalized

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  # Run wilcox1
  p.val=apply(feature_table, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_wilcox_un_large.csv")
```

## 1.9 Wilcoxon rank-sum test: TSS

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  feature_table.scale=apply(feature_table, 2, function(x) x/sum(x))
  
  # Run wilcox2
  p.val=apply(feature_table.scale, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_wilcox_tss_large.csv")
```

# 2. FDR and Power with the Presence of Large Variable Sampling Fractions

```{r, message=FALSE, warning=FALSE, comment=NA}
## Read in original data
dat.ancom_bc=read_csv("../data/sim_poi_gam/large/fdr_power_ancom_bc_large.csv")
dat.ancom=read_csv("../data/sim_poi_gam/large/fdr_power_ancom_large.csv")
dat.deseq2=read_csv("../data/sim_poi_gam/large/fdr_power_deseq2_large.csv")
dat.edger=read_csv("../data/sim_poi_gam/large/fdr_power_edger_large.csv")
dat.zilg=read_csv("../data/sim_poi_gam/large/fdr_power_zilg_large.csv")
dat.zig=read_csv("../data/sim_poi_gam/large/fdr_power_zig_large.csv")
dat.wilcox_un=read_csv("../data/sim_poi_gam/large/fdr_power_wilcox_un_large.csv")
dat.wilcox_tss=read_csv("../data/sim_poi_gam/large/fdr_power_wilcox_tss_large.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)

data_summary = function(eval_data, method){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  data_sum = data.frame(FDR, FDRSD, power, powerSD, simpattern, method)
  data_sum = data_sum%>%unite(n.samp.grp, n.samp.grp1, n.samp.grp2, sep = ", ")
  
  return(data_sum)
}

eval.dat.list = list(dat.ancom_bc, dat.ancom, dat.deseq2, dat.edger, 
                     dat.zilg, dat.zig, dat.wilcox_un, dat.wilcox_tss)
method.list = list("ANCOM-BC", "ANCOM", "DESeq2", "edgeR", "ZILG", "ZIG", "Wilcoxon", "Wilcoxon + TSS")

dat.fig.list = vector(mode = "list", length = length(eval.dat.list))
for (i in 1:length(eval.dat.list)) {
  dat.fig.list[[i]] = data_summary(eval.dat.list[[i]], method.list[[i]])
}

## Merge data
dat.fig=Reduce('rbind', dat.fig.list)
dat.fig$n.samp.grp=factor(dat.fig$n.samp.grp)
levels(dat.fig$n.samp.grp)=c("n = 20/30", "n = 50/50")
dat.fig$method=factor(dat.fig$method)
dat.fig$prop.diff=factor(dat.fig$prop.diff)

dat.fig%>%datatable()%>%formatRound(columns=c("FDR", "FDRSD", "power", "powerSD"), digits=3)
```

## 2.1 Fig. 3b

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=FDR, fill=method)) +
  geom_hline(yintercept=0.05, linetype="dashed", color="black", size = 0.2)+
  scale_y_continuous(breaks = c(0.05, seq(0.2, 1, 0.2)), limits = c(0, 0.8))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="FDR")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.title=element_text(hjust = 0.5),
        strip.background = element_rect(fill="white"),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "b")
ggsave("../figures/Figure 3b.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure 3b.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

## 2.2 Fig. 3c

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=power, fill=method)) +
  scale_y_continuous(breaks = seq(0.2, 1, 0.2), limits = c(0, 1))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="Power")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        strip.background = element_rect(fill="white"),
        plot.title=element_text(hjust = 0.5),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "c")
ggsave("../figures/Figure 3c.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure 3c.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

# 3. FDR and Power with the Presence of Moderate Variable Sampling Fractions

```{r, message=FALSE, warning=FALSE, comment=NA}
## Read in original data
dat.ancom_bc=read_csv("../data/sim_poi_gam/mode/fdr_power_ancom_bc_mode.csv")
dat.ancom=read_csv("../data/sim_poi_gam/mode/fdr_power_ancom_mode.csv")
dat.deseq2=read_csv("../data/sim_poi_gam/mode/fdr_power_deseq2_mode.csv")
dat.edger=read_csv("../data/sim_poi_gam/mode/fdr_power_edger_mode.csv")
dat.zilg=read_csv("../data/sim_poi_gam/mode/fdr_power_zilg_mode.csv")
dat.zig=read_csv("../data/sim_poi_gam/mode/fdr_power_zig_mode.csv")
dat.wilcox_un=read_csv("../data/sim_poi_gam/mode/fdr_power_wilcox_un_mode.csv")
dat.wilcox_tss=read_csv("../data/sim_poi_gam/mode/fdr_power_wilcox_tss_mode.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)

data_summary = function(eval_data, method){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  data_sum = data.frame(FDR, FDRSD, power, powerSD, simpattern, method)
  data_sum = data_sum%>%unite(n.samp.grp, n.samp.grp1, n.samp.grp2, sep = ", ")
  
  return(data_sum)
}

eval.dat.list = list(dat.ancom_bc, dat.ancom, dat.deseq2, dat.edger, 
                     dat.zilg, dat.zig, dat.wilcox_un, dat.wilcox_tss)
method.list = list("ANCOM-BC", "ANCOM", "DESeq2", "edgeR", "ZILG", "ZIG", "Wilcoxon", "Wilcoxon + TSS")

dat.fig.list = vector(mode = "list", length = length(eval.dat.list))
for (i in 1:length(eval.dat.list)) {
  dat.fig.list[[i]] = data_summary(eval.dat.list[[i]], method.list[[i]])
}

## Merge data
dat.fig=Reduce('rbind', dat.fig.list)
dat.fig$n.samp.grp=factor(dat.fig$n.samp.grp)
levels(dat.fig$n.samp.grp)=c("n = 20/30", "n = 50/50")
dat.fig$method=factor(dat.fig$method)
dat.fig$prop.diff=factor(dat.fig$prop.diff)

dat.fig%>%datatable()%>%formatRound(columns=c("FDR", "FDRSD", "power", "powerSD"), digits=3)
```

## 3.1 Fig. S1b

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=FDR, fill=method)) +
  geom_hline(yintercept=0.05, linetype="dashed", color="black", size = 0.2)+
  scale_y_continuous(breaks = c(0.05, seq(0.2, 1, 0.2)), limits = c(0, 0.8))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="FDR")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.title=element_text(hjust = 0.5),
        strip.background = element_rect(fill="white"),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "b")
ggsave("../figures/Figure S1b.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S1b.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

## 3.2 Fig. S1c

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=power, fill=method)) +
  scale_y_continuous(breaks = seq(0.2, 1, 0.2), limits = c(0, 1))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="Power")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        strip.background = element_rect(fill="white"),
        plot.title=element_text(hjust = 0.5),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "c")
ggsave("../figures/Figure S1c.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S1c.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

# 4. FDR and Power with the Presence of Small Variable Sampling Fractions

```{r, message=FALSE, warning=FALSE, comment=NA}
## Read in original data
dat.ancom_bc=read_csv("../data/sim_poi_gam/small/fdr_power_ancom_bc_small.csv")
dat.ancom=read_csv("../data/sim_poi_gam/small/fdr_power_ancom_small.csv")
dat.deseq2=read_csv("../data/sim_poi_gam/small/fdr_power_deseq2_small.csv")
dat.edger=read_csv("../data/sim_poi_gam/small/fdr_power_edger_small.csv")
dat.zilg=read_csv("../data/sim_poi_gam/small/fdr_power_zilg_small.csv")
dat.zig=read_csv("../data/sim_poi_gam/small/fdr_power_zig_small.csv")
dat.wilcox_un=read_csv("../data/sim_poi_gam/small/fdr_power_wilcox_un_small.csv")
dat.wilcox_tss=read_csv("../data/sim_poi_gam/small/fdr_power_wilcox_tss_small.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)

data_summary = function(eval_data, method){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  data_sum = data.frame(FDR, FDRSD, power, powerSD, simpattern, method)
  data_sum = data_sum%>%unite(n.samp.grp, n.samp.grp1, n.samp.grp2, sep = ", ")
  
  return(data_sum)
}

eval.dat.list = list(dat.ancom_bc, dat.ancom, dat.deseq2, dat.edger, 
                     dat.zilg, dat.zig, dat.wilcox_un, dat.wilcox_tss)
method.list = list("ANCOM-BC", "ANCOM", "DESeq2", "edgeR", "ZILG", "ZIG", "Wilcoxon", "Wilcoxon + TSS")

dat.fig.list = vector(mode = "list", length = length(eval.dat.list))
for (i in 1:length(eval.dat.list)) {
  dat.fig.list[[i]] = data_summary(eval.dat.list[[i]], method.list[[i]])
}

## Merge data
dat.fig=Reduce('rbind', dat.fig.list)
dat.fig$n.samp.grp=factor(dat.fig$n.samp.grp)
levels(dat.fig$n.samp.grp)=c("n = 20/30", "n = 50/50")
dat.fig$method=factor(dat.fig$method)
dat.fig$prop.diff=factor(dat.fig$prop.diff)

dat.fig%>%datatable()%>%formatRound(columns=c("FDR", "FDRSD", "power", "powerSD"), digits=3)
```

## 4.1 Fig. S2b

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=FDR, fill=method)) +
  geom_hline(yintercept=0.05, linetype="dashed", color="black", size = 0.2)+
  scale_y_continuous(breaks = c(0.05, seq(0.2, 1, 0.2)), limits = c(0, 0.6))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="FDR")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.title=element_text(hjust = 0.5),
        strip.background = element_rect(fill="white"),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "b")
ggsave("../figures/Figure S2b.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S2b.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

## 4.2 Fig. S2c

```{r, message=FALSE, warning=FALSE, comment=NA}
p=ggplot(dat.fig, aes(x=prop.diff, y=power, fill=method)) +
  scale_y_continuous(breaks = seq(0.2, 1, 0.2), limits = c(0, 1))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="Power")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        strip.background = element_rect(fill="white"),
        plot.title=element_text(hjust = 0.5),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p, labels = "c")
ggsave("../figures/Figure S2c.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S2c.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

# Session information

```{r, message=FALSE, warning=FALSE, comment=NA}
sessionInfo()
devtools::session_info()
```
