---
title: "Figure S6, S7, Table S4, S5"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
rm(list = ls())

library(readxl)
library(tidyverse)
library(ggpubr)
library(DT)
library(pander)
panderOptions('table.caption.prefix', NULL)
panderOptions('table.continues', NULL)
panderOptions('table.emphasize.rownames', FALSE)

source("ancom_bc_v1.0.R")
source("sim_data_poi_gam_two_grp.R")
source("sim_data_poi_gam_multi_grp.R")

data_format1 = function(eval_data){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  
  FDR=signif(FDR, 2); FDRSD=signif(FDRSD, 2)
  power=signif(power, 2); powerSD=signif(powerSD, 2)
  data_sum = data.frame(simpattern, FDR, FDRSD, power, powerSD, row.names = NULL)
  data_sum = data_sum%>%unite(n.samp.grp, n.samp.grp1, n.samp.grp2, sep = "/")%>%
    mutate(prop.diff=prop.diff*100)
  
  return(data_sum)
}

data_format2 = function(eval_data){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  
  FDR=signif(FDR, 2); FDRSD=signif(FDRSD, 2)
  power=signif(power, 2); powerSD=signif(powerSD, 2)
  data_sum = data.frame(simpattern, FDR, FDRSD, power, powerSD, row.names = NULL)
  data_sum = data_sum%>%mutate(prop.diff=prop.diff*100,
                               n.samp.grp=gsub(" ", "/", n.samp.grp))
  
  return(data_sum)
}

data_summary = function(eval_data, method){
  FDR=tapply(as.numeric(eval_data[1, ]), 
             rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  FDRSD=tapply(as.numeric(eval_data[1, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  power=tapply(as.numeric(eval_data[2, ]), 
               rep(seq(nrow(simpattern)), each=iterNum), function(x) mean(x, na.rm = T))
  powerSD=tapply(as.numeric(eval_data[2, ]), 
                 rep(seq(nrow(simpattern)), each=iterNum), function(x) sd(x, na.rm = T))
  data_sum = data.frame(FDR, FDRSD, power, powerSD, simpattern, method)
  data_sum = data_sum%>%unite(n.samp.grp, n.samp.grp1, n.samp.grp2, sep = ", ")
  
  return(data_sum)
}
```

# 1. Small Sample Sizes

## 1.1 Simulation settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, samping fraction variability, and sample size
n.taxa=1000; samp.frac.var="large"; n.samp=c("5_5", "10_10")

# The proportion of differentially abundant taxa
prop.diff=c(0.05, 0.15, 0.25)

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters combinations
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed, samp.frac.var)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed", "samp.frac.var")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", 
                  "abn.seed", "samp.frac.var", "obs.seed")
```

## 1.2 Run simularions

### 1.12 ANCOM-BC

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(4, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_small_samp_ancom_bc.csv")
```

### 1.13 ANCOM

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(10, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  feature.table.origin=test.dat$obs.abn
  
  # Pre-processing
  pre.process=feature_table_pre_process(feature.table.origin, meta.data, 
                                        sample.var="Sample.ID", group.var="group",
                                        zero.cut=0.90, lib.cut=1000, neg.lb = FALSE)
  struc.zero=pre.process$structure.zeros
  num.struc.zero=apply(struc.zero, 1, sum)
  feature.table=pre.process$feature.table
  s0=rownames(feature.table)[which(num.struc.zero==0)]
  s1=rownames(feature.table)[which(num.struc.zero==1)]
  
  # Run ANCOM
  # Format for ANCOM: rows = subjects, cols=taxa
  feature.table.sub=t(feature.table[s0, ])
  
  res.W=ANCOM.main(OTUdat=feature.table.sub, Vardat=meta.data, 
                   main.var="group", sig=0.05, prev.cut=1.01)
  
  res=data.frame(otu.names=c(s0, s1), W_stat=Inf, detected_0.9=TRUE,
                 detected_0.8=TRUE, detected_0.7=TRUE, detected_0.6=TRUE)
  res[match(as.character(res.W$otu.names), res$otu.names), ]=res.W
  res$diff.ind=test.dat$diff.taxa[c(s0, s1)]
  
  # FDR
  FDR=ifelse(sum(res$detected_0.7, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$detected_0.7, 1, 0), na.rm = T)/
               sum(res$detected_0.7, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$detected_0.7, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_small_samp_ancom.csv")
```

### 1.14 DESeq2

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(DESeq2)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for DESeq2
  countdata=test.dat$obs.abn # Format for DESeq2: taxa are rows
  coldata=data.frame(group=as.factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2))))
  rownames(coldata)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  count.table=DESeqDataSetFromMatrix(
    countData = feature_table, colData = coldata, design = ~ group)
  
  # Run DESeq2
  suppressWarnings(dds <- try(DESeq(count.table, quiet = TRUE), silent = TRUE))
  if (inherits(dds, "try-error")) {
    # If the parametric fit failed, try the local.
    suppressWarnings(dds <- try(DESeq(count.table, fitType = "local", quiet = TRUE), silent = TRUE))
    if (inherits(dds, "try-error")) {
      # If local fails, try the mean
      suppressWarnings(dds <- try(DESeq(count.table, fitType = "mean", quiet = TRUE), silent = TRUE))
    }
  }
  if (inherits(dds, "try-error")) {
    # If still bad
    FDR=NA; power=NA
  }else{
    res = results(dds)
    res$id = rownames(res)
    # Some DESeq2 results (for example) had NA adjusted p-values, so replace them with 1
    res[is.na(res[, "padj"]), "padj"] = 1
    
    res=data.frame(taxa=res$id,
                   diff.test=ifelse(res$padj<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)],
                   effec.size=test.dat$effect.size[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
    
  }
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_deseq2.csv")

```

### 1.15 edgeR

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(edgeR)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for edgeR
  groupdata=factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn; meta.data=data.frame(group=groupdata)
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  d=DGEList(counts = countdata, group = groupdata)
  d=calcNormFactors(d)
  design.mat=model.matrix(~ 0 + d$samples$group)
  colnames(design.mat)=levels(d$samples$group)
  
  d=estimateDisp(d, design.mat)
  fit=glmQLFit(d, design.mat)
  qlf=glmQLFTest(fit, contrast=c(1, -1))
  out=data.frame(taxa=rownames(topTags(qlf, n=nrow(countdata))$table), 
                 FDR=topTags(qlf, n=nrow(countdata))$table$FDR)
  out=out[match(rownames(countdata), as.character(out$taxa)), ]
  out$FDR[is.na(out$FDR)]=1
  
  res=data.frame(diff.test=ifelse(out$FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
               sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_edger.csv")
```

### 1.16 metagenomeSeq: Zero-inflated log-normal mixture model (ZILG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  suppressWarnings(fit <- try(fitFeatureModel(obj, mod)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_zilg.csv")
```

### 1.17 metagenomeSeq: Zero-inflated gaussian mixture model (ZIG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  settings = zigControl(maxit = 100, verbose = F)
  suppressWarnings(fit <- try(fitZig(obj, mod, useCSSoffset = T, control = settings)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_zig.csv")
```

### 1.18 Wilcoxon rank-sum test: Unnormalized

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  # Run wilcox1
  p.val=apply(feature_table, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_wilcox_un.csv")
```

### 1.19 Wilcoxon rank-sum test: TSS

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  feature_table.scale=apply(feature_table, 2, function(x) x/sum(x))
  
  # Run wilcox2
  p.val=apply(feature_table.scale, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_small_samp_wilcox_tss.csv")
```

## 1.3 FDR and Power

```{r, message=FALSE, warning=FALSE, comment=NA}
## Read in original data
dat.ancom_bc=read_csv("../data/sim_small_samp/fdr_power_small_samp_ancom_bc.csv")
dat.ancom=read_csv("../data/sim_small_samp/fdr_power_small_samp_ancom.csv")
dat.deseq2=read_csv("../data/sim_small_samp/fdr_power_small_samp_deseq2.csv")
dat.edger=read_csv("../data/sim_small_samp/fdr_power_small_samp_edger.csv")
dat.zilg=read_csv("../data/sim_small_samp/fdr_power_small_samp_zilg.csv")
dat.zig=read_csv("../data/sim_small_samp/fdr_power_small_samp_zig.csv")
dat.wilcox_un=read_csv("../data/sim_small_samp/fdr_power_small_samp_wilcox_un.csv")
dat.wilcox_tss=read_csv("../data/sim_small_samp/fdr_power_small_samp_wilcox_tss.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)

eval.dat.list = list(dat.ancom_bc, dat.ancom, dat.deseq2, dat.edger, 
                     dat.zilg, dat.zig, dat.wilcox_un, dat.wilcox_tss)
method.list = list("ANCOM-BC", "ANCOM", "DESeq2", "edgeR", "ZILG", "ZIG", "Wilcoxon", "Wilcoxon + TSS")

dat.fig.list = vector(mode = "list", length = length(eval.dat.list))
for (i in 1:length(eval.dat.list)) {
  dat.fig.list[[i]] = data_summary(eval.dat.list[[i]], method.list[[i]])
}

## Merge data
dat.fig=Reduce('rbind', dat.fig.list)
dat.fig$n.samp.grp=recode(dat.fig$n.samp.grp, 
                          `5, 5`="n = 5/5", `10, 10`="n = 10/10")
dat.fig$n.samp.grp=factor(dat.fig$n.samp.grp, levels = c("n = 5/5", "n = 10/10"))
dat.fig$method=factor(dat.fig$method)
dat.fig$prop.diff=factor(dat.fig$prop.diff)
dat.fig=dat.fig%>%arrange(method, n.samp.grp)

dat.fig%>%datatable()%>%formatRound(columns=c("FDR", "FDRSD", "power", "powerSD"), digits=3)
```

### 1.31 Fig. S6a

```{r, message=FALSE, warning=FALSE, comment=NA}
p1=ggplot(dat.fig, aes(x=prop.diff, y=FDR, fill=method)) +
  geom_hline(yintercept=0.05, linetype="solid", color="black", size = 0.2)+
  geom_hline(yintercept=0.05+sqrt(0.05*0.95/100), linetype="dashed", color="black", size = 0.2)+
  scale_y_continuous(breaks = c(0.05, seq(0.2, 1, 0.2)), limits = c(0, 0.8))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="FDR")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.title=element_text(hjust = 0.5),
        strip.background = element_rect(fill="white"),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p1, labels = "a")
ggsave("../figures/Figure S6a.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S6a.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

### 1.32 Fig. S6b

```{r, message=FALSE, warning=FALSE, comment=NA}
p2=ggplot(dat.fig, aes(x=prop.diff, y=power, fill=method)) +
  scale_y_continuous(breaks = seq(0.2, 1, 0.2), limits = c(0, 1))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="Power")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        strip.background = element_rect(fill="white"),
        plot.title=element_text(hjust = 0.5),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p2, labels = "b")
ggsave("../figures/Figure S6b.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S6b.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

### 1.33 Fig. S6

```{r, message=FALSE, warning=FALSE, comment=NA, fig.height=10}
p = ggarrange(p1 + labs(x=NULL), p2 + labs(x=NULL),
              labels = c("a", "b"), 
              ncol = 1, nrow = 2,
              common.legend = TRUE, legend="bottom")
annotate_figure(p, left = text_grob("Proportion of Differentially Abundant Taxa", rot = 90))
ggsave("../figures/Figure S6.pdf", width=6.25, height=9, units='in')
ggsave("../figures/Figure S6.jpeg", width=6.25, height=9, units='in', dpi = 300)
```

# 2. Highly Variable Microbial Environment

## 2.1 Simulation settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, library size, and sample size
n.taxa=1000; samp.frac.var="large"; n.samp=c("20_30", "50_50")

# The proportion of differentially abundant taxa
prop.diff=c(0.50, 0.75)

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed, samp.frac.var)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed", "samp.frac.var")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", 
                  "abn.seed", "samp.frac.var", "obs.seed")
```

## 2.2 Run simularions

### 2.12 ANCOM-BC

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(4, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_high_var_ancom_bc.csv")
```

### 2.13 ANCOM

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(10, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  feature.table.origin=test.dat$obs.abn
  
  # Pre-processing
  pre.process=feature_table_pre_process(feature.table.origin, meta.data, 
                                        sample.var="Sample.ID", group.var="group",
                                        zero.cut=0.90, lib.cut=1000, neg.lb = FALSE)
  struc.zero=pre.process$structure.zeros
  num.struc.zero=apply(struc.zero, 1, sum)
  feature.table=pre.process$feature.table
  s0=rownames(feature.table)[which(num.struc.zero==0)]
  s1=rownames(feature.table)[which(num.struc.zero==1)]
  
  # Run ANCOM
  # Format for ANCOM: rows = subjects, cols=taxa
  feature.table.sub=t(feature.table[s0, ])
  
  res.W=ANCOM.main(OTUdat=feature.table.sub, Vardat=meta.data, 
                   main.var="group", sig=0.05, prev.cut=2.01)
  
  res=data.frame(otu.names=c(s0, s1), W_stat=Inf, detected_0.9=TRUE,
                 detected_0.8=TRUE, detected_0.7=TRUE, detected_0.6=TRUE)
  res[match(as.character(res.W$otu.names), res$otu.names), ]=res.W
  res$diff.ind=test.dat$diff.taxa[c(s0, s1)]
  
  # FDR
  FDR=ifelse(sum(res$detected_0.7, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$detected_0.7, 1, 0), na.rm = T)/
               sum(res$detected_0.7, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$detected_0.7, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_high_var_ancom.csv")
```

### 2.14 DESeq2

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(DESeq2)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for DESeq2
  countdata=test.dat$obs.abn # Format for DESeq2: taxa are rows
  coldata=data.frame(group=as.factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2))))
  rownames(coldata)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  count.table=DESeqDataSetFromMatrix(
    countData = feature_table, colData = coldata, design = ~ group)
  
  # Run DESeq2
  suppressWarnings(dds <- try(DESeq(count.table, quiet = TRUE), silent = TRUE))
  if (inherits(dds, "try-error")) {
    # If the parametric fit failed, try the local.
    suppressWarnings(dds <- try(DESeq(count.table, fitType = "local", quiet = TRUE), silent = TRUE))
    if (inherits(dds, "try-error")) {
      # If local fails, try the mean
      suppressWarnings(dds <- try(DESeq(count.table, fitType = "mean", quiet = TRUE), silent = TRUE))
    }
  }
  if (inherits(dds, "try-error")) {
    # If still bad
    FDR=NA; power=NA
  }else{
    res = results(dds)
    res$id = rownames(res)
    # Some DESeq2 results (for example) had NA adjusted p-values, so replace them with 1
    res[is.na(res[, "padj"]), "padj"] = 1
    
    res=data.frame(taxa=res$id,
                   diff.test=ifelse(res$padj<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)],
                   effec.size=test.dat$effect.size[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
    
  }
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_deseq2.csv")

```

### 2.15 edgeR

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(edgeR)
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for edgeR
  groupdata=factor(rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn; meta.data=data.frame(group=groupdata)
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  d=DGEList(counts = countdata, group = groupdata)
  d=calcNormFactors(d)
  design.mat=model.matrix(~ 0 + d$samples$group)
  colnames(design.mat)=levels(d$samples$group)
  
  d=estimateDisp(d, design.mat)
  fit=glmQLFit(d, design.mat)
  qlf=glmQLFTest(fit, contrast=c(1, -1))
  out=data.frame(taxa=rownames(topTags(qlf, n=nrow(countdata))$table), 
                 FDR=topTags(qlf, n=nrow(countdata))$table$FDR)
  out=out[match(rownames(countdata), as.character(out$taxa)), ]
  out$FDR[is.na(out$FDR)]=1
  
  res=data.frame(diff.test=ifelse(out$FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
               sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
    sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_edger.csv")
```

### 2.16 metagenomeSeq: Zero-inflated log-normal mixture model (ZILG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  suppressWarnings(fit <- try(fitFeatureModel(obj, mod)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_zilg.csv")
```

### 2.17 metagenomeSeq: Zero-inflated gaussian mixture model (ZIG)

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(metagenomeSeq)
library(doParallel)
library(foreach)
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  # Prepare data for metagenomeSeq
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  rownames(meta.data)=paste0("sub", seq(n.samp.grp1+n.samp.grp2))
  
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  countdata=countdata[which(taxa.info.ind<zero.threshold), ]+1L
  
  # Run metagenomeSeq
  phenotypeData = AnnotatedDataFrame(meta.data)
  obj = newMRexperiment(countdata, phenoData=phenotypeData, featureData=NULL)
  
  # Calculating normalization factors
  obj = cumNorm(obj)
  
  # Zero-inflated Log-Normal mixture model
  pd = pData(obj)
  mod = model.matrix(~group, data = pd)
  
  settings = zigControl(maxit = 100, verbose = F)
  suppressWarnings(fit <- try(fitZig(obj, mod, useCSSoffset = T, control = settings)))
  if (inherits(fit, "try-error")) {
    power=NA; FDR=NA
  } else{
    out=MRcoefs(fit, number = nrow(countdata))
    out=data.frame(taxa=rownames(out), FDR=out$adjPvalues)
    out=out[match(rownames(countdata), as.character(out$taxa)), ]
    out$FDR[is.na(out$FDR)]=1
    
    res=data.frame(taxa=out$taxa,
                   diff.test=ifelse(out$FDR<0.05, 1, 0), 
                   diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
    FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0,
               sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/
                 sum(res$diff.test==1, na.rm = T))
    power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  
  c(FDR, power)
}
start_time <- Sys.time()

end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_zig.csv")
```

### 2.18 Wilcoxon rank-sum test: Unnormalized

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  
  # Run wilcox1
  p.val=apply(feature_table, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_wilcox_un.csv")
```

### 2.19 Wilcoxon rank-sum test: TSS

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %do% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
                        samp.frac.var)
  
  meta.data=data.frame(group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  countdata=test.dat$obs.abn
  
  zero.threshold=0.90
  taxa.info.ind=apply(countdata, 1, function(x) sum(x==0)/(n.samp.grp1+n.samp.grp2))
  feature_table=round(countdata[which(taxa.info.ind<zero.threshold), ])+1L
  feature_table.scale=apply(feature_table, 2, function(x) x/sum(x))
  
  # Run wilcox2
  p.val=apply(feature_table.scale, 1, function(x) 
    wilcox.test(x[1:n.samp.grp1], x[(n.samp.grp1+1):(n.samp.grp1+n.samp.grp2)])$p.value)
  FDR=p.adjust(p.val, method = "BH")
  
  res=data.frame(diff.test=ifelse(FDR<0.05, 1, 0), 
                 diff.ind=test.dat$diff.taxa[which(taxa.info.ind<zero.threshold)])
  
  # FDR
  FDR=ifelse(sum(res$diff.test==1, na.rm = T)==0, 0, 
             sum(ifelse(res$diff.ind==0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.test==1, na.rm = T))
  
  # Power
  power=sum(ifelse(res$diff.ind!=0&res$diff.test==1, 1, 0), na.rm = T)/sum(res$diff.ind!=0, na.rm = T)
  
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

write_csv(data.frame(simlist), "fdr_power_high_var_wilcox_tss.csv")
```

## 2.3 FDR and Power

```{r, message=FALSE, warning=FALSE, comment=NA}
## Read in original data
dat.ancom_bc=read_csv("../data/sim_high_var/fdr_power_high_var_ancom_bc.csv")
dat.ancom=read_csv("../data/sim_high_var/fdr_power_high_var_ancom.csv")
dat.deseq2=read_csv("../data/sim_high_var/fdr_power_high_var_deseq2.csv")
dat.edger=read_csv("../data/sim_high_var/fdr_power_high_var_edger.csv")
dat.zilg=read_csv("../data/sim_high_var/fdr_power_high_var_zilg.csv")
dat.zig=read_csv("../data/sim_high_var/fdr_power_high_var_zig.csv")
dat.wilcox_un=read_csv("../data/sim_high_var/fdr_power_high_var_wilcox_un.csv")
dat.wilcox_tss=read_csv("../data/sim_high_var/fdr_power_high_var_wilcox_tss.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)

eval.dat.list = list(dat.ancom_bc, dat.ancom, dat.deseq2, dat.edger, 
                     dat.zilg, dat.zig, dat.wilcox_un, dat.wilcox_tss)
method.list = list("ANCOM-BC", "ANCOM", "DESeq2", "edgeR", "ZILG", "ZIG", "Wilcoxon", "Wilcoxon + TSS")

dat.fig.list = vector(mode = "list", length = length(eval.dat.list))
for (i in 1:length(eval.dat.list)) {
  dat.fig.list[[i]] = data_summary(eval.dat.list[[i]], method.list[[i]])
}

## Merge data
dat.fig=Reduce('rbind', dat.fig.list)
dat.fig$n.samp.grp=factor(dat.fig$n.samp.grp)
levels(dat.fig$n.samp.grp)=c("n = 20/30", "n = 50/50")
dat.fig$method=factor(dat.fig$method)
dat.fig$prop.diff=as.character(dat.fig$prop.diff)
dat.fig$prop.diff=recode(dat.fig$prop.diff, `0.5` = "0.50")
dat.fig$prop.diff=factor(dat.fig$prop.diff)

dat.fig%>%datatable()%>%formatRound(columns=c("FDR", "FDRSD", "power", "powerSD"), digits=3)
```

### 2.31 Fig. S7a

```{r, message=FALSE, warning=FALSE, comment=NA}
p1=ggplot(dat.fig, aes(x=prop.diff, y=FDR, fill=method)) +
  geom_hline(yintercept=0.05, linetype="solid", color="black", size = 0.2)+
  geom_hline(yintercept=0.05+sqrt(0.05*0.95/100), linetype="dashed", color="black", size = 0.2)+
  scale_y_continuous(breaks = c(0.05, seq(0.2, 1, 0.2)), limits = c(0, 0.8))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="FDR")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.title=element_text(hjust = 0.5),
        strip.background = element_rect(fill="white"),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p1, labels = "a")
ggsave("../figures/Figure S7a.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S7a.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

### 2.32 Fig. S7b

```{r, message=FALSE, warning=FALSE, comment=NA}
p2=ggplot(dat.fig, aes(x=prop.diff, y=power, fill=method)) +
  scale_y_continuous(breaks = seq(0.2, 1, 0.2), limits = c(0, 1))+
  coord_flip()+facet_grid(.~n.samp.grp)+
  geom_bar(stat="identity", position=position_dodge())+
  labs(x="Proportion of Differentially Abundant Taxa", y="", fill=NULL, title="Power")+
  scale_fill_brewer(palette="Dark2")+
  theme_bw()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        strip.background = element_rect(fill="white"),
        plot.title=element_text(hjust = 0.5),
        legend.position = "bottom")+
  guides(fill=guide_legend(nrow=2, byrow=TRUE))
ggarrange(p2, labels = "b")
ggsave("../figures/Figure S7b.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S7b.jpeg", width=6.25, height=5, units='in', dpi = 300)
```

### 2.33 Fig. S7

```{r, message=FALSE, warning=FALSE, comment=NA, fig.height=10}
p = ggarrange(p1 + labs(x=NULL), p2 + labs(x=NULL),
              labels = c("a", "b"), 
              ncol = 1, nrow = 2,
              common.legend = TRUE, legend="bottom")
annotate_figure(p, left = text_grob("Proportion of Differentially Abundant Taxa", rot = 90))
ggsave("../figures/Figure S7.pdf", width=6.25, height=9, units='in')
ggsave("../figures/Figure S7.jpeg", width=6.25, height=9, units='in', dpi = 300)
```

# 3. Small Number of Taxa

## 3.1 Number of taxa = 10

**Analogous to the OTU table at phylum level.**

### 3.11 Simulation settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, samping fraction variability, and sample size
n.taxa=10; samp.frac.var="large"; n.samp=c("20_30", "50_50")

# The proportion of differentially abundant taxa
prop.diff=0.25

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters combinations
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed, samp.frac.var)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed", "samp.frac.var")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", 
                  "abn.seed", "samp.frac.var", "obs.seed")
```

### 3.12 Run simulations

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(2, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=5000; med.abn=20000; high.abn=1000000; struc.zero.prop=0; out.zero.prop=0
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop, samp.frac.var)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist1), "fdr_power_phylum_ancom_bc.csv")
```

### 3.13 FDR and Power

```{r, message=FALSE, warning=FALSE, comment=NA}
dat.phylum=read_csv("../data/sim_additional/fdr_power_phylum_ancom_bc.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)
sum.phylum=data_format1(dat.phylum)
```

## 3.2 Number of taxa = 50

**Analogous to the OTU table at class/order level**

### 3.21 Simulation settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, samping fraction variability, and sample size
n.taxa=50; samp.frac.var="large"; n.samp=c("20_30", "50_50")

# The proportion of differentially abundant taxa
prop.diff=0.25

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters combinations
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed, samp.frac.var)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed", "samp.frac.var")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", 
                  "abn.seed", "samp.frac.var", "obs.seed")
```

### 3.22 Run simulations

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(2, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp1=as.numeric(params["n.samp.grp1"])
  n.samp.grp2=as.numeric(params["n.samp.grp2"])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  samp.frac.var=params["samp.frac.var"]
  
  # Data generation
  low.abn=500; med.abn=2000; high.abn=100000; struc.zero.prop=0; out.zero.prop=0
  test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop, samp.frac.var)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)), 
                  group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist1), "fdr_power_order_ancom_bc.csv")
```

### 3.23 FDR and Power

```{r, message=FALSE, warning=FALSE, comment=NA}
dat.order=read_csv("../data/sim_additional/fdr_power_order_ancom_bc.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)
sum.order=data_format1(dat.order)
```

## 3.3 Table S5

```{r, message=FALSE, warning=FALSE, comment=NA}
sum.small.taxa = rbind(sum.phylum, sum.order)
colnames(sum.small.taxa)=c("# Taxa", "Sample Size", "Diff (%)", "FDR", "FDRSD", "Power", "PowerSD")

pander(sum.small.taxa)
```

# 4. Multi-Group Comparison

## 4.1 Simulation settings

```{r, message=FALSE, warning=FALSE, comment=NA}
# The number of taxa, samping fraction variability, and sample size
n.taxa=1000; n.samp.grp=c("20 20 30 30", "50 50 50 50")

# The proportion of differentially abundant taxa
prop.diff=c(0.05, 0.15, 0.25)

# Set seeds
iterNum=100
abn.seed=seq(iterNum)

# Define the simulation parameters combinations
simparams=expand.grid(n.taxa, n.samp.grp, prop.diff, abn.seed)
colnames(simparams)=c("n.taxa", "n.samp.grp", "prop.diff", "abn.seed")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%arrange(n.taxa, n.samp.grp, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")

simparamslabels=c("n.taxa", "n.samp.grp", "prop.diff", "abn.seed", "obs.seed")
```

## 4.2 Run simulations

```{r, message=FALSE, warning=FALSE, comment=NA, eval=FALSE}
library(doParallel)
library(foreach)

detectCores()
myCluster=makeCluster(10, type = "FORK")
registerDoParallel(myCluster)

start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
  # i = simparams.list[[1]]
  print(i)
  params = strsplit(i, "_")[[1]]
  names(params) <- simparamslabels
  
  # Paras for data generation
  n.taxa=as.numeric(params["n.taxa"])
  n.samp.grp=as.numeric(str_split(params["n.samp.grp"], " ")[[1]])
  prop.diff=as.numeric(params["prop.diff"])
  abn.seed=as.numeric(params["abn.seed"])
  obs.seed=as.numeric(params["obs.seed"])
  
  # Data generation
  low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.2; out.zero.prop=0.05
  test.dat=abn.tab.gen2(n.taxa, n.samp.grp, low.abn, med.abn, high.abn,
                        prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop)
  obs.abn=test.dat$obs.abn
  meta.data=cbind(Sample.ID=paste0("sub", seq(sum(n.samp.grp))), 
                  group=rep(c(1:length(n.samp.grp)), n.samp.grp))
  
  # Pre-processing
  feature.table=obs.abn; sample.var="Sample.ID"; group.var="group";
  zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
  pre.process=feature_table_pre_process(feature.table, meta.data, sample.var, 
                                        group.var, zero.cut, lib.cut, neg.lb)
  feature.table=pre.process$feature.table
  group.name=pre.process$group.name
  group.ind=pre.process$group.ind
  struc.zero=pre.process$structure.zeros
  
  # Paras for ANCOM-BC
  grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
  tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
  
  # Run ANCOM-BC
  suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
                                       adj.method, tol.EM, max.iterNum, perNum, alpha), 
                              silent = TRUE))
  if (inherits(out, "try-error")) {
    FDR=NA; power=NA
  }else{
    res=cbind(out$res, diff.ind=test.dat$diff.taxa[rownames(out$feature.table)])
    
    # FDR
    FDR=ifelse(sum(res$diff.abn, na.rm = T)==0, 0, 
               sum(ifelse(res$diff.ind==0&res$diff.abn, 1, 0), na.rm = T)/
                 sum(res$diff.abn, na.rm = T))
    
    # Power
    power=sum(ifelse(res$diff.ind!=0&res$diff.abn, 1, 0), na.rm = T)/
      sum(res$diff.ind!=0, na.rm = T)
  }
  c(FDR, power)
}
end_time <- Sys.time()
end_time - start_time

stopCluster(myCluster)
write_csv(data.frame(simlist), "fdr_power_multi_ancom_bc.csv")
```

## 4.3 FDR and Power

```{r, message=FALSE, warning=FALSE, comment=NA}
dat.multi=read_csv("../data/sim_additional/fdr_power_multi_group_ancom_bc.csv")

## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp, prop.diff)

sum.multi=data_format2(dat.multi)
colnames(sum.multi)=c("# Taxa", "Sample Size", "Diff (%)", "FDR", "FDRSD", "Power", "PowerSD")
```

## 4.4 Table S6

```{r, message=FALSE, warning=FALSE, comment=NA}
pander(sum.multi)
```

# Session information

```{r, message=FALSE, warning=FALSE, comment=NA}
sessionInfo()
devtools::session_info()
```

