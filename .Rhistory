feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
pre.process=feature_table_pre_process(feature.table, meta.data, sample.var,
group.var, zero.cut, lib.cut, neg.lb)
feature.table=pre.process$feature.table
group.name=pre.process$group.name
group.ind=pre.process$group.ind
struc.zero=pre.process$structure.zeros
# Paras for ANCOM-BC
grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
n.taxa.raw = nrow(feature.table)
taxa.id.raw = rownames(feature.table)
n.samp = ncol(feature.table)
sample.id = colnames(feature.table)
n.grp = length(grp.ind)
n.samp.grp = sapply(grp.ind, length)
### 0. Discard taxa with structural zeros for the moment
comp.taxa.pos = which(apply(struc.zero, 1, function(x) all(x == 0))) # position of complete taxa (no structural zeros)
O = feature.table[comp.taxa.pos, ]
n.taxa = nrow(O)
taxa.id = rownames(O)
n.samp = ncol(O)
y = as.matrix(log(O + 1))
### 1. Initial estimates of sampling fractions and mean absulute abundances
mu = t(apply(y, 1, function(i) tapply(i, rep(1:n.grp, n.samp.grp), function(j)
mean(j, na.rm = T))))
d = colMeans(y - mu[, rep(1:n.grp, times = n.samp.grp)], na.rm = T)
## Iteration in case of missing values of y
iterNum = 0
epsilon = 100
while (epsilon > tol.EM & iterNum < max.iterNum) {
# Updating mu
mu.new = t(apply(t(t(y) - d), 1, function(i) tapply(i, rep(1:n.grp, n.samp.grp), function(j)
mean(j, na.rm = T))))
# Updating d
d.new = colMeans(y - mu.new[, rep(1:ncol(mu.new), times = n.samp.grp)], na.rm = T)
# Iteration
epsilon = sqrt(sum((mu.new - mu)^2) + sum((d.new - d)^2))
iterNum = iterNum + 1
mu = mu.new
d = d.new
}
mu.var.each = (y-t(t(mu[, rep(1:ncol(mu), times = n.samp.grp)])+d))^2
mu.var = t(apply(mu.var.each, 1, function(x) tapply(x, rep(1:n.grp, n.samp.grp), function(y)
mean(y, na.rm = T))))
sample.size = t(apply(y, 1, function(x)
unlist(tapply(x, rep(1:n.grp, n.samp.grp), function(y) length(y[!is.na(y)])))))
mu.var = mu.var/sample.size
### 2. Estimate the bias (between-group difference of sampling fractions) by E-M algorithm
bias.em.vec = rep(NA, n.grp - 1)
bias.wls.vec = rep(NA, n.grp - 1)
bias.var.vec = rep(NA, n.grp - 1)
for (i in 1:(n.grp-1)) {
Delta = mu[, 1] - mu[, 1+i]
nu = rowSums(mu.var[, c(1, 1+i)])
## 2.1 Initials
pi0_0 = 0.75
pi1_0 = 0.125
pi2_0 = 0.125
delta_0 = mean(Delta[Delta >= quantile(Delta, 0.25, na.rm = T)&
Delta <= quantile(Delta, 0.75, na.rm = T)], na.rm = T)
l1_0 = mean(Delta[Delta < quantile(Delta, 0.125, na.rm = T)], na.rm = T)
l2_0 = mean(Delta[Delta > quantile(Delta, 0.875, na.rm = T)], na.rm = T)
kappa1_0 = var(Delta[Delta < quantile(Delta, 0.125, na.rm = T)], na.rm = T)
if(is.na(kappa1_0)|kappa1_0 == 0) kappa1_0 = 1
kappa2_0 = var(Delta[Delta > quantile(Delta, 0.875, na.rm = T)], na.rm = T)
if(is.na(kappa2_0)|kappa2_0 == 0) kappa2_0 = 1
## 2.2 Apply E-M algorithm
# 2.21 Store all paras in vectors/matrices
pi0.vec = c(pi0_0); pi1.vec = c(pi1_0); pi2.vec = c(pi2_0)
delta.vec = c(delta_0); l1.vec = c(l1_0); l2.vec = c(l2_0)
kappa1.vec = c(kappa1_0); kappa2.vec = c(kappa2_0)
# 2.22 E-M iteration
iterNum = 0
epsilon = 100
while (epsilon > tol.EM & iterNum < max.iterNum) {
# print(iterNum)
## Current value of paras
pi0 = pi0.vec[length(pi0.vec)]; pi1 = pi1.vec[length(pi1.vec)]; pi2 = pi2.vec[length(pi2.vec)]
delta = delta.vec[length(delta.vec)];
l1 = l1.vec[length(l1.vec)]; l2 = l2.vec[length(l2.vec)]
kappa1 = kappa1.vec[length(kappa1.vec)]; kappa2 = kappa2.vec[length(kappa2.vec)]
## E-step
pdf0 = sapply(seq(n.taxa), function(i) dnorm(Delta[i], delta, sqrt(nu[i])))
pdf1 = sapply(seq(n.taxa), function(i) dnorm(Delta[i], delta + l1, sqrt(nu[i] + kappa1)))
pdf2 = sapply(seq(n.taxa), function(i) dnorm(Delta[i], delta + l2, sqrt(nu[i] + kappa2)))
r0i = pi0*pdf0/(pi0*pdf0 + pi1*pdf1 + pi2*pdf2); r0i[is.na(r0i)] = 0
r1i = pi1*pdf1/(pi0*pdf0 + pi1*pdf1 + pi2*pdf2); r1i[is.na(r1i)] = 0
r2i = pi2*pdf2/(pi0*pdf0 + pi1*pdf1 + pi2*pdf2); r2i[is.na(r2i)] = 0
## M-step
pi0_new = mean(r0i, na.rm = T); pi1_new = mean(r1i, na.rm = T); pi2_new = mean(r2i, na.rm = T)
delta_new = sum(r0i*Delta/nu + r1i*(Delta-l1)/(nu+kappa1) + r2i*(Delta-l2)/(nu+kappa2), na.rm = T)/
sum(r0i/nu + r1i/(nu+kappa1) + r2i/(nu+kappa2), na.rm = T)
l1_new = min(sum(r1i*(Delta-delta)/(nu+kappa1), na.rm = T)/sum(r1i/(nu+kappa1), na.rm = T), 0)
l2_new = max(sum(r2i*(Delta-delta)/(nu+kappa2), na.rm = T)/sum(r2i/(nu+kappa2), na.rm = T), 0)
# Nelder-Mead simplex algorithm for kappa1 and kappa2
obj.kappa1 = function(x){
log.pdf = log(sapply(seq(n.taxa), function(i) dnorm(Delta[i], delta+l1, sqrt(nu[i]+x))))
log.pdf[is.infinite(log.pdf)] = 0
-sum(r1i*log.pdf, na.rm = T)
}
kappa1_new = neldermead(x0 = kappa1, fn = obj.kappa1, lower = 0)$par
obj.kappa2 = function(x){
log.pdf = log(sapply(seq(n.taxa), function(i) dnorm(Delta[i], delta+l2, sqrt(nu[i]+x))))
log.pdf[is.infinite(log.pdf)] = 0
-sum(r2i*log.pdf, na.rm = T)
}
kappa2_new = neldermead(x0 = kappa2, fn = obj.kappa2, lower = 0)$par
## Merge to the paras vectors/matrices
pi0.vec = c(pi0.vec, pi0_new); pi1.vec = c(pi1.vec, pi1_new); pi2.vec = c(pi2.vec, pi2_new)
delta.vec = c(delta.vec, delta_new)
l1.vec = c(l1.vec, l1_new); l2.vec = c(l2.vec, l2_new)
kappa1.vec = c(kappa1.vec, kappa1_new); kappa2.vec = c(kappa2.vec, kappa2_new)
## Calculate the new epsilon
epsilon = sqrt((pi0_new-pi0)^2 + (pi1_new-pi1)^2 + (pi2_new-pi2)^2 + (delta_new-delta)^2+
(l1_new-l1)^2 + (l2_new-l2)^2 + (kappa1_new-kappa1)^2 + (kappa2_new-kappa2)^2)
iterNum = iterNum+1
}
# 2.23 Estimate the bias
bias.em.vec[i] = delta.vec[length(delta.vec)]
# 2.24 The WLS estimator of bias
# Cluster 0
C0 = which(Delta >= quantile(Delta, pi1_new, na.rm = T) & Delta < quantile(Delta, 1 - pi2_new, na.rm = T))
# Cluster 1
C1 = which(Delta < quantile(Delta, pi1_new, na.rm = T))
# Cluster 2
C2 = which(Delta >= quantile(Delta, 1 - pi2_new, na.rm = T))
nu_temp = nu
nu_temp[C1] = nu_temp[C1] + kappa1_new
nu_temp[C2] = nu_temp[C2] + kappa2_new
wls.deno = sum(1 / nu_temp)
wls.nume = 1 / nu_temp
wls.nume[C0] = (wls.nume * Delta)[C0]
wls.nume[C1] = (wls.nume * (Delta - l1_new))[C1]
wls.nume[C2] = (wls.nume * (Delta - l2_new))[C2];
wls.nume = sum(wls.nume)
bias.wls.vec[i] = wls.nume / wls.deno
# 2.25 Estimate the variance of bias
bias.var.vec[i] = 1 / wls.deno
if (is.na(bias.var.vec[i])) bias.var.vec[i] = 0
}
bias.em.vec = c(0, bias.em.vec)
bias.wls.vec = c(0, bias.wls.vec)
bias.var.vec
library(tidyverse)
source("scripts/sim_data_poi_gam_two_grp.R")
source("scripts/ancom_bc_v1.0.R")
# The number of taxa, library size, and sample size
n.taxa = 1000; balanced.micro.load = FALSE; balanced.lib.size = TRUE
samp.frac = "small"; n.samp = "20_30"
# The proportion of differentially abundant taxa
prop.diff=c(0.05, 0.15, 0.25, 0.50, 0.75)
# Set seeds
iterNum=100
abn.seed=seq(iterNum)
# Define the simulation parameters
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed,
balanced.micro.load, balanced.lib.size, samp.frac)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed",
"balanced.micro.load", "balanced.lib.size", "samp.frac")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")
simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", "abn.seed",
"balanced.micro.load", "balanced.lib.size", "samp.frac", "obs.seed")
library(doParallel)
library(foreach)
simparams.list=simparams.list[[c(1, 101, 201, 301, 401)]]
simparams.list=simparams.list[c(1, 101, 201, 301, 401)]
simparams.list
start_time <- Sys.time()
simlist=foreach(i = simparams.list, .combine = 'cbind') %dopar% {
# i = simparams.list[[1]]
print(i)
params = strsplit(i, "_")[[1]]
names(params) <- simparamslabels
# Paras for data generation
n.taxa=as.numeric(params["n.taxa"])
n.samp.grp1=as.numeric(params["n.samp.grp1"])
n.samp.grp2=as.numeric(params["n.samp.grp2"])
prop.diff=as.numeric(params["prop.diff"])
abn.seed=as.numeric(params["abn.seed"])
obs.seed=as.numeric(params["obs.seed"])
balanced.micro.load=as.logical(params["balanced.micro.load"])
balanced.lib.size=as.logical(params["balanced.lib.size"])
samp.frac=params["samp.frac"]
# Data generation
low.abn=50; med.abn=200; high.abn=10000; struc.zero.prop=0.20; out.zero.prop=0.05
test.dat=abn.tab.gen1(n.taxa, n.samp.grp1, n.samp.grp2, low.abn, med.abn, high.abn,
prop.diff, abn.seed, obs.seed, struc.zero.prop, out.zero.prop,
balanced.micro.load, balanced.lib.size, samp.frac)
obs.abn=test.dat$obs.abn
meta.data=cbind(Sample.ID=paste0("sub", seq(n.samp.grp1+n.samp.grp2)),
group=rep(c(1, 2), c(n.samp.grp1, n.samp.grp2)))
# Pre-processing
feature.table=obs.abn; sample.var="Sample.ID"; group.var="group"
zero.cut=0.90; lib.cut=1000; neg.lb=FALSE
pre.process=feature_table_pre_process(feature.table, meta.data, sample.var,
group.var, zero.cut, lib.cut, neg.lb)
feature.table=pre.process$feature.table
group.name=pre.process$group.name
group.ind=pre.process$group.ind
struc.zero=pre.process$structure.zeros
# Paras for ANCOM-BC
grp.name=group.name; grp.ind=group.ind; adj.method="bonferroni"
tol.EM=1e-5; max.iterNum=100; perNum=1000; alpha=0.05
# Run ANCOM-BC
suppressWarnings(out <- try(ANCOM_BC(feature.table, grp.name, grp.ind, struc.zero,
adj.method, tol.EM, max.iterNum, perNum, alpha),
silent = TRUE))
if (inherits(out, "try-error")) {
bias.em=NA; bias.wls=NA; bias.diff=NA
}else{
bias.em=out$bias.em[2]; bias.wls=out$bias.wls[2]; bias.diff=bias.em-bias.wls
}
c(bias.em, bias.wls, bias.diff)
}
end_time <- Sys.time()
end_time - start_time
simlist
rm(list = ls())
library(tidyverse)
library(phyloseq)
library(ggpubr)
library(RColorBrewer)
library(DT)
library(pander)
panderOptions('table.caption.prefix', NULL)
panderOptions('table.continues', NULL)
panderOptions('table.emphasize.rownames', FALSE)
source("sim_data_poi_gam_two_grp.R")
source("ancom_bc_v1.0.R")
# The number of taxa, library size, and sample size
n.taxa = 1000; balanced.micro.load = FALSE; balanced.lib.size = TRUE
samp.frac = "small"; n.samp = "20_30"
# The proportion of differentially abundant taxa
prop.diff=c(0.05, 0.15, 0.25, 0.50, 0.75)
# Set seeds
iterNum=100
abn.seed=seq(iterNum)
# Define the simulation parameters
simparams=expand.grid(n.taxa, n.samp, prop.diff, abn.seed,
balanced.micro.load, balanced.lib.size, samp.frac)
colnames(simparams)=c("n.taxa", "n.samp", "prop.diff", "abn.seed",
"balanced.micro.load", "balanced.lib.size", "samp.frac")
simparams=simparams%>%mutate(obs.seed=abn.seed+1)
simparams=simparams%>%separate(col = n.samp, into = c("n.samp.grp1", "n.samp.grp2"), sep = "_")
simparams=simparams%>%arrange(n.taxa, n.samp.grp1, prop.diff, abn.seed, obs.seed)
simparams.list=apply(simparams, 1, paste0, collapse="_")
simparamslabels=c("n.taxa", "n.samp.grp1", "n.samp.grp2","prop.diff", "abn.seed",
"balanced.micro.load", "balanced.lib.size", "samp.frac", "obs.seed")
## Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
## Reshaping data
simpattern=distinct(simparams, n.taxa, n.samp.grp1, n.samp.grp2, prop.diff)
View(simpattern)
View(p.df)
p.df = t(p.df)
View(p.df)
colnames(p.df) = c("em", "wls", "diff")
View(p.df)
p.df = p.df%>%mutate(prop = rep(prop.diff, each = iterNum))
## Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
p.df = data.frame(t(p.df))
colnames(p.df) = c("em", "wls", "diff")
p.df = p.df%>%mutate(prop = rep(prop.diff, each = iterNum))
View(p.df)
txt.df = data.frame(prop = prop.diff,
corr = NA)
View(txt.df)
cor.test(p.df$em, p.df$wls)
temp = cor.test(p.df$em, p.df$wls)
temp$statistic
temp$estimate
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
View(txt.df)
temp$p.value
txt.df$p = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$p.value)
View(txt.df)
txt.df = txt.df%>%mutate(label = paste0("Corr = ", corr, " (p < .001)"))
txt.df = txt.df%>%mutate_each(label = paste0("Corr = ", corr, " (p < .001)"))
txt.df$label = paste0("Corr = ", round(corr, 2), " (p < .001)")
txt.df$label = paste0("Corr = ", round(txt.df$corr, 2), " (p < .001)")
paste0("Corr = ", round(txt.df$corr, 2), " (p < .001)")
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
prop.diff
data.frame(prop = prop.diff, corr = NA, p = NA)
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
View(txt.df)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
View(txt.df)
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)%>%.$estimate)
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate%>%.$corr)
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls))
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
# Annotation data
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
txt.df$p = p.df%>%group_by(prop)%>%summarise(p = cor.test(em, wls)$p.value)%>%.$p
View(txt.df)
txt.df$label = paste0("Corr = ", round(txt.df$corr, 2), " (p < .001)")
View(txt.df)
txt.df = txt.df%>%mutate(p.level = ifelse(p < .001, "p < .001", round(p, 3)),
label = paste0("Corr = ", round(corr, 2), " (", p.level, ")"))
View(txt.df)
txt.df = data.frame(prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
txt.df$p = p.df%>%group_by(prop)%>%summarise(p = cor.test(em, wls)$p.value)%>%.$p
txt.df = txt.df%>%mutate(p.level = ifelse(p < .001, "p < .001", round(p, 3)),
label = paste0("Corr = ", round(corr, 2), " (", p.level, ")"))
View(txt.df)
txt.df$prop = factor(txt.df$prop, levels = prop.diff)
txt.df$prop
p.df$prop = factor(p.df$prop, levels = prop.diff)
p.df
View(p.df)
View(simpattern)
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator"))+
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label, color = NULL,group= NULL))
p
txt.df = data.frame(em = 0.2, wls = 0.25, prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
txt.df$p = p.df%>%group_by(prop)%>%summarise(p = cor.test(em, wls)$p.value)%>%.$p
txt.df = txt.df%>%mutate(level = ifelse(p < .001, "p < .001", round(p, 3)),
label = paste0("Corr = ", round(corr, 2), " (", level, ")"))
txt.df$prop = factor(txt.df$prop, levels = prop.diff)
p.df$prop = factor(p.df$prop, levels = prop.diff)
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label, color = NULL,group= NULL))
p
?facet_wrap
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue") +
facet_wrap(.~prop, nrow = 2, scales = "free")+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label, color = NULL,group= NULL))
p
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue") +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label, color = NULL,group= NULL))
p
txt.df = data.frame(em = -0.5, wls = 0.4, prop = prop.diff, corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
txt.df$p = p.df%>%group_by(prop)%>%summarise(p = cor.test(em, wls)$p.value)%>%.$p
txt.df = txt.df%>%mutate(level = ifelse(p < .001, "p < .001", round(p, 3)),
label = paste0("Corr = ", round(corr, 2), " (", level, ")"))
txt.df$prop = factor(txt.df$prop, levels = prop.diff)
p.df$prop = factor(p.df$prop, levels = prop.diff)
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue") +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label))
p
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue", alpha = 0.9) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label))
p
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue", linetype="dashed") +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label))
p
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue", linetype="dashed") +
scale_x_continuous(breaks = seq(-0.8, 0.4, 0.4), limits = c(-0.85, 0.45)) +
scale_y_continuous(breaks = seq(-0.8, 0.4, 0.4), limits = c(-0.85, 0.45)) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label))
p
# Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
View(p.df)
p.df = p.df[, -1:100]
p.df = p.df[, -(1:100)]
View(p.df)
View(p.df)
colnames(p.df) = paste0("result", 1:400)
View(p.df)
colnames(p.df) = paste0("result.", 1:400)
View(p.df)
write.csv(p.df, "../data/sim_additional/em_vs_wls.csv")
# Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
View(p.df)
# Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
View(p.df)
# Read in original data
p.df = read_csv("../data/sim_additional/em_vs_wls.csv")
# Reshape data
p.df = data.frame(t(p.df))
colnames(p.df) = c("em", "wls", "diff")
p.df = p.df%>%mutate(prop = rep(paste0(prop.diff*100, "%"), each = iterNum))
paste0(prop.diff*100, "%")
# The proportion of differentially abundant taxa
prop.diff=c(0.15, 0.25, 0.50, 0.75)
p.df = p.df%>%mutate(prop = rep(paste0(prop.diff*100, "%"), each = iterNum))
View(p.df)
txt.df = data.frame(em = -0.5, wls = 0.4, prop = paste0(prop.diff*100, "%"), corr = NA, p = NA)
txt.df$corr = p.df%>%group_by(prop)%>%summarise(corr = cor.test(em, wls)$estimate)%>%.$corr
txt.df$p = p.df%>%group_by(prop)%>%summarise(p = cor.test(em, wls)$p.value)%>%.$p
txt.df = txt.df%>%mutate(level = ifelse(p < .001, "p < .001", round(p, 3)),
label = paste0("Corr = ", round(corr, 2), " (", level, ")"))
View(txt.df)
txt.df$prop
txt.df$prop = factor(txt.df$prop)
txt.df$prop
p.df$prop = factor(p.df$prop)
p.df$prop
p=ggplot(p.df, aes(em, wls)) + geom_point(size = 0.3) +
geom_abline(slope = 1, intercept = 0, color = "steelblue", linetype="dashed") +
scale_x_continuous(breaks = seq(-0.8, 0.4, 0.4), limits = c(-0.85, 0.45)) +
scale_y_continuous(breaks = seq(-0.8, 0.4, 0.4), limits = c(-0.85, 0.45)) +
facet_wrap(.~prop, nrow = 2)+
labs(x="EM estimator", y="WLS estimator")+
theme_bw()+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = "bottom",
strip.background = element_rect(fill="white"))+
guides(color = guide_legend(override.aes = list(size=3)))+
geom_text(data = txt.df, mapping = aes(x = em, y = wls, label = label))
p
ggsave("../figures/Figure S9.pdf", width=6.25, height=5, units='in')
ggsave("../figures/Figure S9.jpeg", width=6.25, height=5, units='in', dpi = 300)
